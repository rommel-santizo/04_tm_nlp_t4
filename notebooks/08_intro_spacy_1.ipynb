{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy (https://spacy.io)\n",
    "\n",
    "Spacy es una librería moderna para procesamiento de lenguaje natural. Los objetos de la librería son objetos con un sentido lingüistico relevante.\n",
    "\n",
    "## Instalación\n",
    "\n",
    "Para instalar spacy, creamos y activamos un entorno nuevo primero,\n",
    "\n",
    "```\n",
    "conda create -n spacy\n",
    "\n",
    "conda activate spacy\n",
    "```\n",
    "\n",
    "Dentro del entorno, instalamos las librerías generales que vamos a necesitar,\n",
    "````\n",
    "conda install python jupyter notebook\n",
    "pip install -U spacy\n",
    "pip install -U spacy-lookups-data\n",
    "python -m spacy download en_core_web_lg\n",
    "python -m spacy download es_core_news_lg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros pasos\n",
    "\n",
    "Primero importamos la clase de algún lenguaje, por ejemplo, inglés o español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto `nlp`, con el cual vamos a procesar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un documento, que es mucho más que simplemente texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_en = nlp_en('The dog barks under the Moon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nlp` es una instancia de una clase de tipo `English`, mientras que `doc` es una instancia de una clase `spacy.tokens.doc.Doc`, que se inicializa con un `str`. La instancia resultante, precisamente como instancia de clase, tiene un conjunto de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog barks under the Moon\n"
     ]
    }
   ],
   "source": [
    "print(doc_en.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando inicializamos `nlp` sobre un `str`, **spacy** crea un objeto de tipo `Doc` y tokeniza el texto que le damos. El objeto resultante se puede indexar y sus elementos son precisamente los tokens en que el texto se divide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(doc_en[0])\n",
    "print(type(doc_en[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "dog\n",
      "barks\n",
      "under\n",
      "the\n",
      "Moon\n"
     ]
    }
   ],
   "source": [
    "for token in doc_en:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varios índices consecutivos del documento dan pie a un `Span`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = doc_en[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog barks under\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print(slice.text)\n",
    "print(type(slice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos léxicos\n",
    "\n",
    "Además de la separación en tokens, la clase `Token` contiene además un conjunto de atributos que permiten caracterizar la naturaleza del token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es import Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_es = Spanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número 1990 encontrado\n"
     ]
    }
   ],
   "source": [
    "doc_es = nlp_es(\n",
    "    \"En 1990, más del 60% de las personas en Asia Oriental vivían en pobreza extrema. \"\n",
    "    \"Ahora menos del 4% viven en pobreza extrema.\"\n",
    ")\n",
    "\n",
    "for token in doc_es:\n",
    "    if token.like_num:\n",
    "        print(f'Número {token.text} encontrado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número 1990 encontrado\n",
      "Número 60 encontrado\n",
      "Número 4 encontrado\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc_en = nlp_en(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "for token in doc_en:\n",
    "    if token.like_num:\n",
    "        print(f'Número {token.text} encontrado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos visto propiedades de los tokens asociadas estrictamente al **léxico**, es decir, a las propiedades aisladas que pueden ser encontradas en el diccionario. Más adelante veremos propiedades **contextuales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma: En \t\t Norm: en\n",
      "Lemma: 1990 \t\t Norm: 1990\n",
      "Lemma: , \t\t Norm: ,\n",
      "Lemma: más \t\t Norm: más\n",
      "Lemma: del \t\t Norm: del\n",
      "Lemma: 60% \t\t Norm: 60%\n",
      "Lemma: de \t\t Norm: de\n",
      "Lemma: los \t\t Norm: las\n",
      "Lemma: personar \t\t Norm: personas\n",
      "Lemma: en \t\t Norm: en\n",
      "Lemma: Asia \t\t Norm: asia\n",
      "Lemma: Oriental \t\t Norm: oriental\n",
      "Lemma: vivir \t\t Norm: vivían\n",
      "Lemma: en \t\t Norm: en\n",
      "Lemma: pobreza \t\t Norm: pobreza\n",
      "Lemma: extremo \t\t Norm: extrema\n",
      "Lemma: . \t\t Norm: .\n",
      "Lemma: Ahora \t\t Norm: ahora\n",
      "Lemma: menos \t\t Norm: menos\n",
      "Lemma: del \t\t Norm: del\n",
      "Lemma: 4% \t\t Norm: 4%\n",
      "Lemma: vivir \t\t Norm: viven\n",
      "Lemma: en \t\t Norm: en\n",
      "Lemma: pobreza \t\t Norm: pobreza\n",
      "Lemma: extremo \t\t Norm: extrema\n",
      "Lemma: . \t\t Norm: .\n"
     ]
    }
   ],
   "source": [
    "for token in doc_es:\n",
    "    print(f'Lemma: {token.lemma_} \\t\\t Norm: {token.norm_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para referencia: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
